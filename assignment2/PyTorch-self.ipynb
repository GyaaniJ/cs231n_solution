{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train = True, \n",
    "                             download = True, transform = T.ToTensor())\n",
    "loader = DataLoader(cifar10_train, batch_size = 64, shuffle = False, \n",
    "                    num_workers=2)\n",
    "\n",
    "mean = 0\n",
    "std = 0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    data = data[0]\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1),-1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "    \n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean.tolist(),std.tolist())\n",
    "])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train = True,\n",
    "                             download= True, transform= transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "                          sampler= sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train = True, download = True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "                        sampler = sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train = False, download = True,\n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test,batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening: \n",
      " tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0]\n",
    "    return x.view(N,-1)\n",
    "\n",
    "x = torch.arange(12).view(2,1,3,2)\n",
    "print('After flattening: \\n', flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_fc (x, params):\n",
    "    x = flatten(x)\n",
    "    w1, w2 = params\n",
    "    x = F.relu(x.mm(w1))\n",
    "    x= x.mm(w2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    \n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    \n",
    "    conv1 = F.conv2d(x, conv_w1 , conv_b1, padding=2)\n",
    "    relu1 = F.relu(conv1)\n",
    "    conv2 = F.conv2d(conv1, conv_w2, conv_b2, padding=1)\n",
    "    relu2 = F.relu(conv2)\n",
    "    relu2_flat = torch.flatten(relu2,1,-1)\n",
    "    scores = relu2_flat.mm(fc_w)+fc_b\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b1 = torch.zeros((6,))  # out_channel\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b2 = torch.zeros((9,))  # out_channel\n",
    "\n",
    "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
    "    fc_b = torch.zeros(10)\n",
    "\n",
    "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weight(shape):\n",
    "    if len(shape) == 2:\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:])\n",
    "    w = torch.randn(shape, device = device, dtype=dtype)*np.sqrt(2. / fan_in)\n",
    "    w.requires_grad  = True\n",
    "    return w\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device , dtype= dtype, requires_grad=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part2(loader, model_fn, params):\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print(f'Checking accuracy on the {split} set')\n",
    "    num_correct, num_samples = 0,0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device = device, dtype = dtype)\n",
    "            y = y.to(device = device, dtype = dtype)\n",
    "            scores = model_fn(x, params)\n",
    "            _ , preds = torch.max(scores, dim =1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float (num_correct)/num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' %(num_correct, num_samples, 100* acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part2(model_fn, params, learning_rate):\n",
    "    for t, (x,y) in enumerate(loader_train):\n",
    "        x = x.to(device = device, dtype= dtype)\n",
    "        y = y.to(device = device, dtype = torch.int64)\n",
    "        scores = model_fn(x, params)\n",
    "        loss = F.cross_entropy(scores,y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "                w.grad.zero_()\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' %(t, loss.item()))\n",
    "            check_accuracy_part2(loader_val, model_fn, params)\n",
    "            print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 4.3042\n",
      "Checking accuracy on the val set\n",
      "Got 139 / 1000 correct (13.90%)\n",
      "\n",
      "Iteration 100, loss = 2.4231\n",
      "Checking accuracy on the val set\n",
      "Got 363 / 1000 correct (36.30%)\n",
      "\n",
      "Iteration 200, loss = 1.7054\n",
      "Checking accuracy on the val set\n",
      "Got 318 / 1000 correct (31.80%)\n",
      "\n",
      "Iteration 300, loss = 1.9891\n",
      "Checking accuracy on the val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Iteration 400, loss = 1.6583\n",
      "Checking accuracy on the val set\n",
      "Got 406 / 1000 correct (40.60%)\n",
      "\n",
      "Iteration 500, loss = 1.9078\n",
      "Checking accuracy on the val set\n",
      "Got 435 / 1000 correct (43.50%)\n",
      "\n",
      "Iteration 600, loss = 1.8850\n",
      "Checking accuracy on the val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 700, loss = 1.8756\n",
      "Checking accuracy on the val set\n",
      "Got 451 / 1000 correct (45.10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size,10))\n",
    "\n",
    "train_part2(two_layer_fc, [w1,w2],learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.2595\n",
      "Checking accuracy on the val set\n",
      "Got 437 / 1000 correct (43.70%)\n",
      "\n",
      "Iteration 100, loss = 1.4550\n",
      "Checking accuracy on the val set\n",
      "Got 480 / 1000 correct (48.00%)\n",
      "\n",
      "Iteration 200, loss = 1.3386\n",
      "Checking accuracy on the val set\n",
      "Got 469 / 1000 correct (46.90%)\n",
      "\n",
      "Iteration 300, loss = 1.1238\n",
      "Checking accuracy on the val set\n",
      "Got 463 / 1000 correct (46.30%)\n",
      "\n",
      "Iteration 400, loss = 1.5193\n",
      "Checking accuracy on the val set\n",
      "Got 474 / 1000 correct (47.40%)\n",
      "\n",
      "Iteration 500, loss = 1.5016\n",
      "Checking accuracy on the val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n",
      "Iteration 600, loss = 1.3309\n",
      "Checking accuracy on the val set\n",
      "Got 480 / 1000 correct (48.00%)\n",
      "\n",
      "Iteration 700, loss = 1.3966\n",
      "Checking accuracy on the val set\n",
      "Got 466 / 1000 correct (46.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_part2(two_layer_fc, [w1,w2],learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.5002\n",
      "Checking accuracy on the val set\n",
      "Got 122 / 1000 correct (12.20%)\n",
      "\n",
      "Iteration 100, loss = 2.1151\n",
      "Checking accuracy on the val set\n",
      "Got 385 / 1000 correct (38.50%)\n",
      "\n",
      "Iteration 200, loss = 1.8424\n",
      "Checking accuracy on the val set\n",
      "Got 405 / 1000 correct (40.50%)\n",
      "\n",
      "Iteration 300, loss = 1.7020\n",
      "Checking accuracy on the val set\n",
      "Got 455 / 1000 correct (45.50%)\n",
      "\n",
      "Iteration 400, loss = 1.4370\n",
      "Checking accuracy on the val set\n",
      "Got 468 / 1000 correct (46.80%)\n",
      "\n",
      "Iteration 500, loss = 1.8262\n",
      "Checking accuracy on the val set\n",
      "Got 448 / 1000 correct (44.80%)\n",
      "\n",
      "Iteration 600, loss = 1.3755\n",
      "Checking accuracy on the val set\n",
      "Got 463 / 1000 correct (46.30%)\n",
      "\n",
      "Iteration 700, loss = 1.4467\n",
      "Checking accuracy on the val set\n",
      "Got 501 / 1000 correct (50.10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "conv_w1 = None\n",
    "conv_b1 = None\n",
    "conv_w2 = None\n",
    "conv_b2 = None\n",
    "fc_w = None\n",
    "fc_b = None\n",
    "\n",
    "conv_w1 = random_weight((channel_1, 3, 5, 5))\n",
    "conv_b1 = zero_weight((channel_1,))\n",
    "conv_w2 = random_weight((channel_2, channel_1, 3,3))\n",
    "conv_b2 = zero_weight((channel_2))\n",
    "fc_w = random_weight((channel_2 * 32 * 32, 10))\n",
    "fc_b = zero_weight((10,))\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__ (self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size , num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc = nn.Linear(channel_2 * 32 * 32, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv2(F.relu(self.conv1(x))))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        scores = self.fc(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():\n",
    "    model = ThreeLayerConvNet(in_channel=3, channel_1=32, channel_2=16, num_classes=10)\n",
    "    x = torch.randn(64, 3, 32, 32)  # minibatch size 64, 3 channels (RGB), 32x32 images\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0,0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device = device, dtype= dtype)\n",
    "            y = y.to(device = device, dtype = torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct)/num_samples\n",
    "        print('Got %d / %d correct %.2f%%' %(num_correct,num_samples, 100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs =1):\n",
    "    model = model.to(device = device)\n",
    "    for e in range(epochs):\n",
    "        for t,(x,y)in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x = x.to(device= device, dtype= dtype)\n",
    "            y = y.to(device= device, dtype = torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores,y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' %(t, loss.item()))\n",
    "                check_accuracy_part34(loader_val,model)\n",
    "                print()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.3899\n",
      "Checking accuracy on the val set\n",
      "Got 143 / 1000 correct 14.30%\n",
      "\n",
      "Iteration 100, loss = 2.0971\n",
      "Checking accuracy on the val set\n",
      "Got 354 / 1000 correct 35.40%\n",
      "\n",
      "Iteration 200, loss = 1.9965\n",
      "Checking accuracy on the val set\n",
      "Got 358 / 1000 correct 35.80%\n",
      "\n",
      "Iteration 300, loss = 2.1168\n",
      "Checking accuracy on the val set\n",
      "Got 361 / 1000 correct 36.10%\n",
      "\n",
      "Iteration 400, loss = 1.7581\n",
      "Checking accuracy on the val set\n",
      "Got 371 / 1000 correct 37.10%\n",
      "\n",
      "Iteration 500, loss = 1.8092\n",
      "Checking accuracy on the val set\n",
      "Got 412 / 1000 correct 41.20%\n",
      "\n",
      "Iteration 600, loss = 1.5403\n",
      "Checking accuracy on the val set\n",
      "Got 427 / 1000 correct 42.70%\n",
      "\n",
      "Iteration 700, loss = 1.5010\n",
      "Checking accuracy on the val set\n",
      "Got 444 / 1000 correct 44.40%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "model = TwoLayerFC(3 *32 *32, hidden_layer_size, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "train_part34(model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.1101\n",
      "Checking accuracy on the val set\n",
      "Got 552 / 1000 correct 55.20%\n",
      "\n",
      "Iteration 100, loss = 0.0923\n",
      "Checking accuracy on the val set\n",
      "Got 542 / 1000 correct 54.20%\n",
      "\n",
      "Iteration 200, loss = 0.1455\n",
      "Checking accuracy on the val set\n",
      "Got 539 / 1000 correct 53.90%\n",
      "\n",
      "Iteration 300, loss = 0.0727\n",
      "Checking accuracy on the val set\n",
      "Got 550 / 1000 correct 55.00%\n",
      "\n",
      "Iteration 400, loss = 0.0737\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 500, loss = 0.0764\n",
      "Checking accuracy on the val set\n",
      "Got 552 / 1000 correct 55.20%\n",
      "\n",
      "Iteration 600, loss = 0.0771\n",
      "Checking accuracy on the val set\n",
      "Got 555 / 1000 correct 55.50%\n",
      "\n",
      "Iteration 700, loss = 0.0742\n",
      "Checking accuracy on the val set\n",
      "Got 550 / 1000 correct 55.00%\n",
      "\n",
      "Iteration 0, loss = 0.1016\n",
      "Checking accuracy on the val set\n",
      "Got 542 / 1000 correct 54.20%\n",
      "\n",
      "Iteration 100, loss = 0.0550\n",
      "Checking accuracy on the val set\n",
      "Got 555 / 1000 correct 55.50%\n",
      "\n",
      "Iteration 200, loss = 0.0598\n",
      "Checking accuracy on the val set\n",
      "Got 556 / 1000 correct 55.60%\n",
      "\n",
      "Iteration 300, loss = 0.1001\n",
      "Checking accuracy on the val set\n",
      "Got 566 / 1000 correct 56.60%\n",
      "\n",
      "Iteration 400, loss = 0.0696\n",
      "Checking accuracy on the val set\n",
      "Got 568 / 1000 correct 56.80%\n",
      "\n",
      "Iteration 500, loss = 0.1099\n",
      "Checking accuracy on the val set\n",
      "Got 554 / 1000 correct 55.40%\n",
      "\n",
      "Iteration 600, loss = 0.0456\n",
      "Checking accuracy on the val set\n",
      "Got 556 / 1000 correct 55.60%\n",
      "\n",
      "Iteration 700, loss = 0.0882\n",
      "Checking accuracy on the val set\n",
      "Got 564 / 1000 correct 56.40%\n",
      "\n",
      "Iteration 0, loss = 0.0976\n",
      "Checking accuracy on the val set\n",
      "Got 553 / 1000 correct 55.30%\n",
      "\n",
      "Iteration 100, loss = 0.0481\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 200, loss = 0.1144\n",
      "Checking accuracy on the val set\n",
      "Got 555 / 1000 correct 55.50%\n",
      "\n",
      "Iteration 300, loss = 0.1135\n",
      "Checking accuracy on the val set\n",
      "Got 547 / 1000 correct 54.70%\n",
      "\n",
      "Iteration 400, loss = 0.1004\n",
      "Checking accuracy on the val set\n",
      "Got 559 / 1000 correct 55.90%\n",
      "\n",
      "Iteration 500, loss = 0.0482\n",
      "Checking accuracy on the val set\n",
      "Got 570 / 1000 correct 57.00%\n",
      "\n",
      "Iteration 600, loss = 0.0537\n",
      "Checking accuracy on the val set\n",
      "Got 545 / 1000 correct 54.50%\n",
      "\n",
      "Iteration 700, loss = 0.0677\n",
      "Checking accuracy on the val set\n",
      "Got 554 / 1000 correct 55.40%\n",
      "\n",
      "Iteration 0, loss = 0.0439\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 100, loss = 0.0755\n",
      "Checking accuracy on the val set\n",
      "Got 554 / 1000 correct 55.40%\n",
      "\n",
      "Iteration 200, loss = 0.0425\n",
      "Checking accuracy on the val set\n",
      "Got 554 / 1000 correct 55.40%\n",
      "\n",
      "Iteration 300, loss = 0.0517\n",
      "Checking accuracy on the val set\n",
      "Got 559 / 1000 correct 55.90%\n",
      "\n",
      "Iteration 400, loss = 0.0539\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 500, loss = 0.0453\n",
      "Checking accuracy on the val set\n",
      "Got 553 / 1000 correct 55.30%\n",
      "\n",
      "Iteration 600, loss = 0.0769\n",
      "Checking accuracy on the val set\n",
      "Got 554 / 1000 correct 55.40%\n",
      "\n",
      "Iteration 700, loss = 0.0549\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 0, loss = 0.0351\n",
      "Checking accuracy on the val set\n",
      "Got 558 / 1000 correct 55.80%\n",
      "\n",
      "Iteration 100, loss = 0.0496\n",
      "Checking accuracy on the val set\n",
      "Got 570 / 1000 correct 57.00%\n",
      "\n",
      "Iteration 200, loss = 0.0501\n",
      "Checking accuracy on the val set\n",
      "Got 561 / 1000 correct 56.10%\n",
      "\n",
      "Iteration 300, loss = 0.0726\n",
      "Checking accuracy on the val set\n",
      "Got 560 / 1000 correct 56.00%\n",
      "\n",
      "Iteration 400, loss = 0.0790\n",
      "Checking accuracy on the val set\n",
      "Got 550 / 1000 correct 55.00%\n",
      "\n",
      "Iteration 500, loss = 0.0319\n",
      "Checking accuracy on the val set\n",
      "Got 558 / 1000 correct 55.80%\n",
      "\n",
      "Iteration 600, loss = 0.0561\n",
      "Checking accuracy on the val set\n",
      "Got 560 / 1000 correct 56.00%\n",
      "\n",
      "Iteration 700, loss = 0.0603\n",
      "Checking accuracy on the val set\n",
      "Got 560 / 1000 correct 56.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_part34(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.7688\n",
      "Checking accuracy on the val set\n",
      "Got 116 / 1000 correct 11.60%\n",
      "\n",
      "Iteration 100, loss = 1.7705\n",
      "Checking accuracy on the val set\n",
      "Got 343 / 1000 correct 34.30%\n",
      "\n",
      "Iteration 200, loss = 1.7883\n",
      "Checking accuracy on the val set\n",
      "Got 380 / 1000 correct 38.00%\n",
      "\n",
      "Iteration 300, loss = 1.4381\n",
      "Checking accuracy on the val set\n",
      "Got 421 / 1000 correct 42.10%\n",
      "\n",
      "Iteration 400, loss = 1.3594\n",
      "Checking accuracy on the val set\n",
      "Got 443 / 1000 correct 44.30%\n",
      "\n",
      "Iteration 500, loss = 1.6429\n",
      "Checking accuracy on the val set\n",
      "Got 476 / 1000 correct 47.60%\n",
      "\n",
      "Iteration 600, loss = 1.5164\n",
      "Checking accuracy on the val set\n",
      "Got 484 / 1000 correct 48.40%\n",
      "\n",
      "Iteration 700, loss = 1.5828\n",
      "Checking accuracy on the val set\n",
      "Got 483 / 1000 correct 48.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = ThreeLayerConvNet(in_channel=3, channel_1=32, channel_2=16, num_classes=10)\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3536\n",
      "Checking accuracy on the val set\n",
      "Got 169 / 1000 correct 16.90%\n",
      "\n",
      "Iteration 100, loss = 1.7509\n",
      "Checking accuracy on the val set\n",
      "Got 393 / 1000 correct 39.30%\n",
      "\n",
      "Iteration 200, loss = 1.7583\n",
      "Checking accuracy on the val set\n",
      "Got 418 / 1000 correct 41.80%\n",
      "\n",
      "Iteration 300, loss = 1.9626\n",
      "Checking accuracy on the val set\n",
      "Got 418 / 1000 correct 41.80%\n",
      "\n",
      "Iteration 400, loss = 1.6779\n",
      "Checking accuracy on the val set\n",
      "Got 424 / 1000 correct 42.40%\n",
      "\n",
      "Iteration 500, loss = 2.0461\n",
      "Checking accuracy on the val set\n",
      "Got 438 / 1000 correct 43.80%\n",
      "\n",
      "Iteration 600, loss = 1.8734\n",
      "Checking accuracy on the val set\n",
      "Got 445 / 1000 correct 44.50%\n",
      "\n",
      "Iteration 700, loss = 1.5013\n",
      "Checking accuracy on the val set\n",
      "Got 444 / 1000 correct 44.40%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0),-1)\n",
    "    \n",
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * 32*32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size,10)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate,\n",
    "                      momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3282\n",
      "Checking accuracy on the val set\n",
      "Got 137 / 1000 correct 13.70%\n",
      "\n",
      "Iteration 100, loss = 1.6690\n",
      "Checking accuracy on the val set\n",
      "Got 429 / 1000 correct 42.90%\n",
      "\n",
      "Iteration 200, loss = 1.5154\n",
      "Checking accuracy on the val set\n",
      "Got 468 / 1000 correct 46.80%\n",
      "\n",
      "Iteration 300, loss = 1.5724\n",
      "Checking accuracy on the val set\n",
      "Got 500 / 1000 correct 50.00%\n",
      "\n",
      "Iteration 400, loss = 1.3488\n",
      "Checking accuracy on the val set\n",
      "Got 520 / 1000 correct 52.00%\n",
      "\n",
      "Iteration 500, loss = 1.2996\n",
      "Checking accuracy on the val set\n",
      "Got 533 / 1000 correct 53.30%\n",
      "\n",
      "Iteration 600, loss = 1.1008\n",
      "Checking accuracy on the val set\n",
      "Got 579 / 1000 correct 57.90%\n",
      "\n",
      "Iteration 700, loss = 1.3165\n",
      "Checking accuracy on the val set\n",
      "Got 588 / 1000 correct 58.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0),-1)\n",
    "    \n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=channel_1, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel_1, out_channels=channel_2, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2 *32 *32,10)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on the test set\n",
      "Got 5719 / 10000 correct 57.19%\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
